{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = 5\n",
    "hiddens = 10\n",
    "outputs = 3\n",
    "batch_size = 10\n",
    "tests = 100\n",
    "neurons = inputs + hiddens + outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, derivative=False):\n",
    "    gt = (x > 0)\n",
    "    if derivative:\n",
    "        return 1 * gt\n",
    "    else:\n",
    "        return x * gt\n",
    "\n",
    "\n",
    "def derivate(grad, state, t):\n",
    "    sn = np.zeros(shape=grad.shape)\n",
    "    sn[:,np.eye(neurons).astype(bool)] = state[:,np.newaxis]\n",
    "    sn = np.transpose(sn, (0,3,2,1))\n",
    "    return f(t, derivative=True)[:, np.newaxis, np.newaxis] * (np.matmul(grad, np_A) + sn)\n",
    "\n",
    "def softmax(x):\n",
    "    exps = np.exp(x - np.max(x))\n",
    "    return exps / np.expand_dims(np.sum(exps, axis=1), axis=1)\n",
    "\n",
    "\n",
    "def ce_loss(out, y, grad):\n",
    "    y = y.astype(int)\n",
    "    m = y.shape[0]\n",
    "    p = softmax(out)\n",
    "    log_likelihood = -np.log(p[range(m),y])\n",
    "    loss = np.mean(log_likelihood, axis=0)\n",
    "\n",
    "    de = p\n",
    "    de[range(m),y] -= 1\n",
    "    de = de/m\n",
    "    de = np.expand_dims(np.expand_dims(de, axis=2), axis=2)\n",
    "    grad = de*grad\n",
    "\n",
    "    return (loss, grad.sum(axis=1).sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Numpy and pytorch forward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_net(state, grad, x, bs=batch_size, compute_grad=True):\n",
    "    state[:,0:inputs] = x\n",
    "    t = np.matmul(state, np_A)\n",
    "    grad = derivate(grad, state, t) if compute_grad else None\n",
    "    state = f(t)\n",
    "    return state, grad\n",
    "\n",
    "def tc_net(state, x):\n",
    "    state[:,0:inputs] = x\n",
    "    t = torch.matmul(state, tc_A)\n",
    "    state = torch.relu(t)\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compute absolute errors between numpy and pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test():\n",
    "    ticks = random.randint(1, 3)\n",
    "    np_input_batch = np.random.rand(ticks, batch_size, inputs)\n",
    "    tc_input_batch = torch.tensor(np_input_batch).float()\n",
    "\n",
    "    np_output_batch = np.random.randint(0, outputs, (batch_size,))\n",
    "    tc_output_batch = torch.tensor(np_output_batch)\n",
    "\n",
    "    np_state = np.zeros((batch_size, neurons))\n",
    "    tc_state = torch.zeros(batch_size, neurons)\n",
    "\n",
    "    grad = np.zeros((batch_size, neurons, neurons, neurons))\n",
    "\n",
    "    for i in range(0, ticks):\n",
    "        np_state, grad = np_net(np_state, grad, np_input_batch[i])\n",
    "        tc_state = tc_net(tc_state, tc_input_batch[i])\n",
    "    \n",
    "    grad = np.transpose(grad, (0,3,1,2))\n",
    "    \n",
    "    state_err = np.abs(tc_state.detach().numpy() - np_state).sum()\n",
    "\n",
    "    np_outs = np_state[:,inputs+hiddens:neurons]\n",
    "    tc_outs = tc_state[:,inputs+hiddens:neurons]\n",
    "\n",
    "    outs_grad = grad[:,inputs+hiddens:neurons]\n",
    "\n",
    "    np_loss, err_grad = ce_loss(np_outs, np_output_batch, outs_grad)\n",
    "\n",
    "    tc_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    tc_loss = tc_loss_fn(tc_outs, tc_output_batch)\n",
    "    tc_loss.backward()\n",
    "\n",
    "    err_grad[:,:inputs] = 0\n",
    "    # Ignore input weigths gradients\n",
    "    err_grad[:inputs, :] = 0\n",
    "    tc_A.grad[:inputs, :] = 0\n",
    "\n",
    "    grad_err = np.abs(tc_A.grad.numpy() - err_grad).sum()\n",
    "\n",
    "    return state_err, grad_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 0 \tState absolute error: 0.000084\t\tGradient absolute error: 0.000001\n",
      "Test: 1 \tState absolute error: 0.000080\t\tGradient absolute error: 0.000003\n",
      "Test: 2 \tState absolute error: 0.000065\t\tGradient absolute error: 0.000001\n",
      "Test: 3 \tState absolute error: 0.000085\t\tGradient absolute error: 0.000001\n",
      "Test: 4 \tState absolute error: 0.000522\t\tGradient absolute error: 0.000009\n",
      "Test: 5 \tState absolute error: 0.000396\t\tGradient absolute error: 0.000023\n",
      "Test: 6 \tState absolute error: 0.000595\t\tGradient absolute error: 0.000014\n",
      "Test: 7 \tState absolute error: 0.000633\t\tGradient absolute error: 0.000010\n",
      "Test: 8 \tState absolute error: 0.000596\t\tGradient absolute error: 0.000092\n",
      "Test: 9 \tState absolute error: 0.000008\t\tGradient absolute error: 0.000000\n",
      "Test: 10 \tState absolute error: 0.000380\t\tGradient absolute error: 0.000005\n",
      "Test: 11 \tState absolute error: 0.000568\t\tGradient absolute error: 0.000121\n",
      "Test: 12 \tState absolute error: 0.000470\t\tGradient absolute error: 0.000006\n",
      "Test: 13 \tState absolute error: 0.000080\t\tGradient absolute error: 0.000000\n",
      "Test: 14 \tState absolute error: 0.000562\t\tGradient absolute error: 0.000013\n",
      "Test: 15 \tState absolute error: 0.000405\t\tGradient absolute error: 0.000012\n",
      "Test: 16 \tState absolute error: 0.000083\t\tGradient absolute error: 0.000003\n",
      "Test: 17 \tState absolute error: 0.000090\t\tGradient absolute error: 0.000001\n",
      "Test: 18 \tState absolute error: 0.000085\t\tGradient absolute error: 0.000001\n",
      "Test: 19 \tState absolute error: 0.000006\t\tGradient absolute error: 0.000000\n",
      "Test: 20 \tState absolute error: 0.000441\t\tGradient absolute error: 0.000005\n",
      "Test: 21 \tState absolute error: 0.000083\t\tGradient absolute error: 0.000001\n",
      "Test: 22 \tState absolute error: 0.000079\t\tGradient absolute error: 0.000001\n",
      "Test: 23 \tState absolute error: 0.000481\t\tGradient absolute error: 0.000013\n",
      "Test: 24 \tState absolute error: 0.000087\t\tGradient absolute error: 0.000002\n",
      "Test: 25 \tState absolute error: 0.000565\t\tGradient absolute error: 0.000011\n",
      "Test: 26 \tState absolute error: 0.000009\t\tGradient absolute error: 0.000000\n",
      "Test: 27 \tState absolute error: 0.000007\t\tGradient absolute error: 0.000000\n",
      "Test: 28 \tState absolute error: 0.000484\t\tGradient absolute error: 0.000015\n",
      "Test: 29 \tState absolute error: 0.000071\t\tGradient absolute error: 0.000001\n",
      "Test: 30 \tState absolute error: 0.000416\t\tGradient absolute error: 0.000009\n",
      "Test: 31 \tState absolute error: 0.000089\t\tGradient absolute error: 0.000001\n",
      "Test: 32 \tState absolute error: 0.000580\t\tGradient absolute error: 0.000014\n",
      "Test: 33 \tState absolute error: 0.000436\t\tGradient absolute error: 0.000009\n",
      "Test: 34 \tState absolute error: 0.000008\t\tGradient absolute error: 0.000000\n",
      "Test: 35 \tState absolute error: 0.000084\t\tGradient absolute error: 0.000001\n",
      "Test: 36 \tState absolute error: 0.000078\t\tGradient absolute error: 0.000001\n",
      "Test: 37 \tState absolute error: 0.000073\t\tGradient absolute error: 0.000003\n",
      "Test: 38 \tState absolute error: 0.000096\t\tGradient absolute error: 0.000001\n",
      "Test: 39 \tState absolute error: 0.000008\t\tGradient absolute error: 0.000000\n",
      "Test: 40 \tState absolute error: 0.000067\t\tGradient absolute error: 0.000001\n",
      "Test: 41 \tState absolute error: 0.000521\t\tGradient absolute error: 0.000009\n",
      "Test: 42 \tState absolute error: 0.000691\t\tGradient absolute error: 0.000102\n",
      "Test: 43 \tState absolute error: 0.000009\t\tGradient absolute error: 0.000000\n",
      "Test: 44 \tState absolute error: 0.000086\t\tGradient absolute error: 0.000001\n",
      "Test: 45 \tState absolute error: 0.000078\t\tGradient absolute error: 0.000001\n",
      "Test: 46 \tState absolute error: 0.000393\t\tGradient absolute error: 0.000053\n",
      "Test: 47 \tState absolute error: 0.000540\t\tGradient absolute error: 0.000008\n",
      "Test: 48 \tState absolute error: 0.000080\t\tGradient absolute error: 0.000005\n",
      "Test: 49 \tState absolute error: 0.000085\t\tGradient absolute error: 0.000003\n",
      "Test: 50 \tState absolute error: 0.000008\t\tGradient absolute error: 0.000000\n",
      "Test: 51 \tState absolute error: 0.000079\t\tGradient absolute error: 0.000001\n",
      "Test: 52 \tState absolute error: 0.000556\t\tGradient absolute error: 0.000045\n",
      "Test: 53 \tState absolute error: 0.000560\t\tGradient absolute error: 0.000013\n",
      "Test: 54 \tState absolute error: 0.000092\t\tGradient absolute error: 0.000001\n",
      "Test: 55 \tState absolute error: 0.000082\t\tGradient absolute error: 0.000001\n",
      "Test: 56 \tState absolute error: 0.000008\t\tGradient absolute error: 0.000000\n",
      "Test: 57 \tState absolute error: 0.000083\t\tGradient absolute error: 0.000002\n",
      "Test: 58 \tState absolute error: 0.000090\t\tGradient absolute error: 0.000001\n",
      "Test: 59 \tState absolute error: 0.000088\t\tGradient absolute error: 0.000001\n",
      "Test: 60 \tState absolute error: 0.000079\t\tGradient absolute error: 0.000002\n",
      "Test: 61 \tState absolute error: 0.000009\t\tGradient absolute error: 0.000000\n",
      "Test: 62 \tState absolute error: 0.000527\t\tGradient absolute error: 0.000064\n",
      "Test: 63 \tState absolute error: 0.000067\t\tGradient absolute error: 0.000002\n",
      "Test: 64 \tState absolute error: 0.000085\t\tGradient absolute error: 0.000002\n",
      "Test: 65 \tState absolute error: 0.000007\t\tGradient absolute error: 0.000000\n",
      "Test: 66 \tState absolute error: 0.000525\t\tGradient absolute error: 0.000013\n",
      "Test: 67 \tState absolute error: 0.000099\t\tGradient absolute error: 0.000002\n",
      "Test: 68 \tState absolute error: 0.000090\t\tGradient absolute error: 0.000002\n",
      "Test: 69 \tState absolute error: 0.000678\t\tGradient absolute error: 0.000125\n",
      "Test: 70 \tState absolute error: 0.000512\t\tGradient absolute error: 0.000011\n",
      "Test: 71 \tState absolute error: 0.000076\t\tGradient absolute error: 0.000002\n",
      "Test: 72 \tState absolute error: 0.000637\t\tGradient absolute error: 0.000008\n",
      "Test: 73 \tState absolute error: 0.000008\t\tGradient absolute error: 0.000000\n",
      "Test: 74 \tState absolute error: 0.000007\t\tGradient absolute error: 0.000000\n",
      "Test: 75 \tState absolute error: 0.000589\t\tGradient absolute error: 0.000013\n",
      "Test: 76 \tState absolute error: 0.000088\t\tGradient absolute error: 0.000001\n",
      "Test: 77 \tState absolute error: 0.000007\t\tGradient absolute error: 0.000000\n",
      "Test: 78 \tState absolute error: 0.000551\t\tGradient absolute error: 0.000015\n",
      "Test: 79 \tState absolute error: 0.000006\t\tGradient absolute error: 0.000000\n",
      "Test: 80 \tState absolute error: 0.000507\t\tGradient absolute error: 0.000018\n",
      "Test: 81 \tState absolute error: 0.000007\t\tGradient absolute error: 0.000000\n",
      "Test: 82 \tState absolute error: 0.000006\t\tGradient absolute error: 0.000000\n",
      "Test: 83 \tState absolute error: 0.000098\t\tGradient absolute error: 0.000002\n",
      "Test: 84 \tState absolute error: 0.000552\t\tGradient absolute error: 0.000013\n",
      "Test: 85 \tState absolute error: 0.000619\t\tGradient absolute error: 0.000009\n",
      "Test: 86 \tState absolute error: 0.000008\t\tGradient absolute error: 0.000000\n",
      "Test: 87 \tState absolute error: 0.000008\t\tGradient absolute error: 0.000000\n",
      "Test: 88 \tState absolute error: 0.000080\t\tGradient absolute error: 0.000001\n",
      "Test: 89 \tState absolute error: 0.000090\t\tGradient absolute error: 0.000001\n",
      "Test: 90 \tState absolute error: 0.000008\t\tGradient absolute error: 0.000000\n",
      "Test: 91 \tState absolute error: 0.000093\t\tGradient absolute error: 0.000001\n",
      "Test: 92 \tState absolute error: 0.000098\t\tGradient absolute error: 0.000003\n",
      "Test: 93 \tState absolute error: 0.000653\t\tGradient absolute error: 0.000155\n",
      "Test: 94 \tState absolute error: 0.000624\t\tGradient absolute error: 0.000014\n",
      "Test: 95 \tState absolute error: 0.000534\t\tGradient absolute error: 0.000009\n",
      "Test: 96 \tState absolute error: 0.000008\t\tGradient absolute error: 0.000000\n",
      "Test: 97 \tState absolute error: 0.000008\t\tGradient absolute error: 0.000000\n",
      "Test: 98 \tState absolute error: 0.000106\t\tGradient absolute error: 0.000002\n",
      "Test: 99 \tState absolute error: 0.000615\t\tGradient absolute error: 0.000007\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, tests):\n",
    "    np_A = np.random.rand(neurons, neurons)\n",
    "    tc_A = torch.tensor(np_A).float().requires_grad_(True)\n",
    "\n",
    "    state_err, grad_err = run_test()\n",
    "    print(\"Test: %d \\tState absolute error: %f\\t\\tGradient absolute error: %f\" % (i, state_err, grad_err))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
